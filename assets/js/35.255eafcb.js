(window.webpackJsonp=window.webpackJsonp||[]).push([[35],{340:function(s,t,a){s.exports=a.p+"assets/img/dbscan1.a5f9aee1.png"},445:function(s,t,a){"use strict";a.r(t);var n=a(3),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"dbscan-密度聚类算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dbscan-密度聚类算法"}},[s._v("#")]),s._v(" DBSCAN 密度聚类算法")]),s._v(" "),t("h2",{attrs:{id:"_1-dbscan原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-dbscan原理"}},[s._v("#")]),s._v(" 1. DBSCAN原理")]),s._v(" "),t("ol",[t("li",[s._v("DBSCAN(Density-Based Spatial Clustering of Applications with Noise, 具有噪声的基于密度的聚类方法)")]),s._v(" "),t("li",[s._v("密度聚类原理: 通过将紧密相连的样本划分为一类, 这样就得到了一个聚类类别. 通过将所有各组紧密想来你的样本划为各个不同的类别, 就得到的最终的聚类结果")]),s._v(" "),t("li",[s._v("优点\n"),t("ol",[t("li",[s._v("不需要设置分类个数")]),s._v(" "),t("li",[s._v("适用于任意形状数据")]),s._v(" "),t("li",[s._v("对异常点数据不敏感")]),s._v(" "),t("li",[s._v("聚类结果没有偏倚")])])]),s._v(" "),t("li",[s._v("缺点\n"),t("ol",[t("li",[s._v("样本密度不均匀, 聚类间距相差很大时, 聚类效果较差")]),s._v(" "),t("li",[s._v("样本集较大时, 聚类收敛时间较长")]),s._v(" "),t("li",[s._v("调参相对复杂")])])])]),s._v(" "),t("h2",{attrs:{id:"_2-源码"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-源码"}},[s._v("#")]),s._v(" 2. 源码")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("基于sklearn的DBSCAN")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("datasets "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" make_circles"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" make_blobs\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pyplot "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cluster "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" DBSCAN\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建数据集")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 环形分布数据: 样本点数, 内圈外圈距离之比, 噪声点的标准差")]),s._v("\nx1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" make_circles"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n_samples"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" factor"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" noise"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".05")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 团状分布数据: 样本点数, 数据维度, 中心点, 标准差")]),s._v("\nx2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" make_blobs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n_samples"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" n_features"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" centers"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" cluster_std"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 数组拼接")]),s._v("\nx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("concatenate"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# eps: 邻域的距离阈值, 默认0.5")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# min_samples: 领域的样本数阈值, 默认值5")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# metric: 最近邻距离度量参数, 默认欧氏距离")]),s._v("\ny_pred "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" DBSCAN"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("eps"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fit_predict"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("scatter"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" c"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("y_pred"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br")])])]),s._v(" "),t("li",[t("p",[s._v("效果")]),s._v(" "),t("p",[t("img",{attrs:{src:a(340),alt:"dbscan1"}})])])])])}),[],!1,null,null,null);t.default=e.exports}}]);