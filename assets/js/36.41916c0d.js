(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{248:function(s,t,a){s.exports=a.p+"assets/img/k-means1.6bca06c5.png"},448:function(s,t,a){"use strict";a.r(t);var n=a(3),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"k-means-聚类算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#k-means-聚类算法"}},[s._v("#")]),s._v(" K-Means 聚类算法")]),s._v(" "),t("h2",{attrs:{id:"_1-k-means-简介"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-k-means-简介"}},[s._v("#")]),s._v(" 1. K-Means 简介")]),s._v(" "),t("ol",[t("li",[s._v("K-Means 原理: 对于给定的样本集，按照样本之间的距离大小，将样本集划分为K个簇。让簇内的点尽量紧密的连在一起，而让簇间的距离尽量的大")]),s._v(" "),t("li",[s._v("传统 K-Means 流程\n"),t("ol",[t("li",[s._v("选择k值")]),s._v(" "),t("li",[s._v("随机选择k个初始化质心")]),s._v(" "),t("li",[s._v("计算样本到各个质心的距离, 按照距离最小划分类别")]),s._v(" "),t("li",[s._v("重新选择质心, 重复第3步骤")]),s._v(" "),t("li",[s._v("若质心向量不变则输出分区, 负责重新选择质心")])])]),s._v(" "),t("li",[s._v("K-Means++ 算法\n"),t("ol",[t("li",[s._v("质心优化: 第一个质心随机选择, 与当前质心距离较远的点被选择聚类中心的概率较大")])])]),s._v(" "),t("li",[s._v("K-Means 距离计算优化 elkan\n"),t("ol",[t("li",[s._v("目的是减少不必要的距离计算")]),s._v(" "),t("li",[s._v("原理:三角形两边之和大于等于第三边, 两边只差小于第三边\n"),t("ol",[t("li",[s._v("如果预先知道两个质心的距离D(j1, j2), 若点x到满足2D(x, j1) < D(x, j2), 则D(x, j1) < D(x, j2)")]),s._v(" "),t("li",[s._v("D(x, j1) ≥ max{0, D(x, j1)-D(j1, j2)}")])])]),s._v(" "),t("li",[s._v("样本稀疏的情况下不适用")])])]),s._v(" "),t("li",[s._v("大样本优化 Mini Batch K-Means\n"),t("ol",[t("li",[s._v("用样本中的一部分样本(batch size)来做传统的K-Means")]),s._v(" "),t("li",[s._v("精度会有所下降, 一般会多跑几次, 选择最优")])])])]),s._v(" "),t("h2",{attrs:{id:"_2-源码"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-源码"}},[s._v("#")]),s._v(" 2. 源码")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("基于sklearn的K-Means算法")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cluster "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" KMeans\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pyplot "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("datasets "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" make_blobs\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建数据集")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# x为样本特征, y为样本簇类别, 1000样本, 每个样本两个特征")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 共4个簇, 簇中心为[1, 1], [1, -1], [-1, 1], [-1, -1], 簇方差为分别[0.4, 0.4, 0.2, 0.2]")]),s._v("\nx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" make_blobs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n_samples"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" n_features"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" centers"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n               cluster_std"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# plt.scatter(x[:, 0], x[:, 1], marker='o')")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# plt.show()")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# n_clusters: K值")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# max_iter: 最大迭代次数")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# n_init: 用不同初始化之心运行算法的次数, 默认10. K较大时可适当增大")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# init: 初始值选择方式, 随机选择'random', 优化过的'k-means++', 一般用默认的'k-means++'")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# algorithm: 'auto', 'full', 'elkan'三种选择, 一般用默认'auto'")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# random_state: 用于随机产生中心的随机序列")]),s._v("\ny_pred "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" KMeans"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n_clusters"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" random_state"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fit_predict"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 下面三行与上面这句等价")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# km = KMeans(n_clusters=4, random_state=2)")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# km.fit(x)")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# y_pred = km.predict(x)")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("scatter"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" c"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("y_pred"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br")])])]),s._v(" "),t("li",[t("p",[s._v("输出结果")]),s._v(" "),t("p",[t("img",{attrs:{src:a(248),alt:"k-means1"}})])])]),s._v(" "),t("h2",{attrs:{id:"_3-参考"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-参考"}},[s._v("#")]),s._v(" 3. 参考")]),s._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://www.cnblogs.com/pinard/p/6164214.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("K-Means聚类算法原理🔗"),t("OutboundLink")],1)])])])}),[],!1,null,null,null);t.default=e.exports}}]);